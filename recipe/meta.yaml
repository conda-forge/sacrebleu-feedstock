{% set name = "sacrebleu" %}
{% set version = "2.5.0" %}

package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  url: https://pypi.org/packages/source/{{ name[0] }}/{{ name }}/{{ name }}-{{ version }}.tar.gz
  sha256: af3cc432508cbf2fc8c20da1f7f6d675bce8168bedf466e296ccf27da9404bf1
  patches:
    - no_changelog.patch

build:
  noarch: python
  number: 0
  script: {{ PYTHON }} -m pip install . -vv
  entry_points:
    - sacrebleu = sacrebleu.sacrebleu:main

requirements:
  host:
    - python >=3.6
    - pip
  run:
    - python >=3.6
    - typing
    - portalocker
    - regex
    - tabulate >=0.8.9
    - numpy >=1.17
    - colorama
    - lxml
    # extras_require={'ja': ['mecab-python3==1.0.3', 'ipadic>=1.0,<2.0']},

test:
  imports:
    - sacrebleu

about:
  home: https://github.com/mjpost/sacrebleu
  license: Apache-2.0
  license_file: LICENSE.txt
  summary: Reference BLEU implementation that auto-downloads test sets and reports a version string to facilitate cross-lab comparisons

  description: |
    SacreBLEU (Post, 2018) provides hassle-free computation of shareable,
    comparable, and reproducible BLEU scores. Inspired by Rico Sennrich's
    multi-bleu-detok.perl, it produces the official WMT scores but works with
    plain text. It also knows all the standard test sets and handles
    downloading, processing, and tokenization for you.

extra:
  recipe-maintainers:
    - hmaarrfk
